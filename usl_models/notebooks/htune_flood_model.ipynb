{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Model Training Notebook\n",
    "\n",
    "Train a Flood ConvLSTM Model using `usl_models` lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "import time\n",
    "import keras\n",
    "import logging\n",
    "from usl_models.flood_ml import constants\n",
    "from usl_models.flood_ml.model import FloodModel\n",
    "from usl_models.flood_ml.model_params import FloodModelParams\n",
    "from usl_models.flood_ml.dataset import load_dataset_windowed, load_dataset\n",
    "import os\n",
    "# Setup\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "keras.utils.set_random_seed(812)\n",
    "\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"   \n",
    "# timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# def filter_by_mean_label_value(dataset, mean_threshold=0.001):\n",
    "#     \"\"\"Keep samples where the mean of the label tensor ≤ threshold.\"\"\"\n",
    "#     def filter_fn(input_dict, label):\n",
    "#         return tf.reduce_mean(label) <= mean_threshold\n",
    "#     return dataset.filter(filter_fn)\n",
    "\n",
    "# def mask_outliers_in_label(dataset, outlier_threshold=0.02):\n",
    "#     \"\"\"Zero out or NaN out pixels above threshold in the label tensor.\"\"\"\n",
    "#     def map_fn(input_dict, label):\n",
    "#         mask = label <= outlier_threshold\n",
    "#         masked_label = tf.where(mask, label, tf.zeros_like(label))  # or tf.constant(np.nan)\n",
    "#         return input_dict, masked_label\n",
    "#     return dataset.map(map_fn)\n",
    "\n",
    "# Cities and their config folders\n",
    "city_config_mapping = {\n",
    "    \"Manhattan\": \"Manhattan_config\",\n",
    "    # #  \"Atlanta\": \"Atlanta_config\",\n",
    "    # \"Phoenix_SM\": \"PHX_SM\",\n",
    "    # \"Phoenix_PV\": \"PHX_PV\",\n",
    "}\n",
    "\n",
    "# Rainfall files you want\n",
    "rainfall_files = [5, 6]  # Only 5 and 6\n",
    "\n",
    "# Generate sim_names\n",
    "sim_names = []\n",
    "for city, config in city_config_mapping.items():\n",
    "    for rain_id in rainfall_files:\n",
    "        sim_name = f\"{city}-{config}/Rainfall_Data_{rain_id}.txt\"\n",
    "        sim_names.append(sim_name)\n",
    "\n",
    "print(f\"Training on {len(sim_names)} simulations.\")\n",
    "for s in sim_names:\n",
    "    print(s)\n",
    "\n",
    "# Now load dataset\n",
    "train_dataset = load_dataset_windowed(\n",
    "    sim_names=sim_names,\n",
    "    batch_size=4,\n",
    "    dataset_split='train'\n",
    ").cache()\n",
    "\n",
    "validation_dataset = load_dataset_windowed(\n",
    "    sim_names=sim_names,\n",
    "    batch_size=4,\n",
    "    dataset_split='val'\n",
    ").cache()\n",
    "\n",
    "# print(\"\\n=== Sample mean flood values BEFORE filtering train ===\")\n",
    "# for i, (_, label) in enumerate(train_dataset.take(20)):\n",
    "#     print(f\"Sample {i}: mean flood = {tf.reduce_mean(label).numpy():.5f}\")\n",
    "\n",
    "# print(\"\\n=== Sample mean flood values BEFORE filtering val ===\")\n",
    "# for i, (_, label) in enumerate(validation_dataset.take(20)):\n",
    "#     print(f\"Sample {i}: mean flood = {tf.reduce_mean(label).numpy():.5f}\")\n",
    "\n",
    "# Filter and cache\n",
    "# train_dataset = filter_by_mean_label_value(train_dataset, mean_threshold=0.001)\n",
    "# train_dataset = mask_outliers_in_label(train_dataset, outlier_threshold=0.02)\n",
    "\n",
    "# validation_dataset = filter_by_mean_label_value(validation_dataset, mean_threshold=0.001)\n",
    "# validation_dataset = mask_outliers_in_label(validation_dataset, outlier_threshold=0.02)\n",
    "\n",
    "# Count examples to ensure not empty\n",
    "n_train = sum(1 for _ in train_dataset)\n",
    "n_val = sum(1 for _ in validation_dataset)\n",
    "# print(f\"Filtered training samples: {n_train}\")\n",
    "# print(f\"Filtered validation samples: {n_val}\")\n",
    "\n",
    "\n",
    "if n_train == 0 or n_val == 0:\n",
    "    raise ValueError(\"Filtered dataset is empty! Lower threshold or check label range.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Collect all label pixel values (flattened) from train and val\n",
    "# all_values = []\n",
    "\n",
    "# for dataset in [train_dataset, validation_dataset]:\n",
    "#     for _, label in dataset.take(20):  # limit to first 20 samples\n",
    "#         label_np = label.numpy()\n",
    "#         all_values.append(label_np.flatten())\n",
    "\n",
    "# # Concatenate all into a single 1D array\n",
    "# flood_pixels = np.concatenate(all_values)\n",
    "# flood_pixels = flood_pixels[~np.isnan(flood_pixels)]  # remove NaNs\n",
    "\n",
    "# # Histogram (linear scale)\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.hist(flood_pixels, bins=100, color=\"steelblue\", alpha=0.8)\n",
    "# plt.title(\"Flood Depth Distribution (linear scale)\")\n",
    "# plt.xlabel(\"Flood Depth (m)\")\n",
    "# plt.ylabel(\"Pixel Count\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Histogram (log scale)\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.hist(flood_pixels, bins=100, color=\"tomato\", alpha=0.8, log=True)\n",
    "# plt.title(\"Flood Depth Distribution (log scale)\")\n",
    "# plt.xlabel(\"Flood Depth (m)\")\n",
    "# plt.ylabel(\"Log Pixel Count\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Flood Pixel Statistics:\")\n",
    "# print(f\"Min: {flood_pixels.min():.4f}\")\n",
    "# print(f\"Mean: {flood_pixels.mean():.4f}\")\n",
    "# print(f\"Median: {np.median(flood_pixels):.4f}\")\n",
    "# print(f\"Max: {flood_pixels.max():.4f}\")\n",
    "# print(f\"90th percentile: {np.percentile(flood_pixels, 90):.4f}\")\n",
    "# print(f\"99th percentile: {np.percentile(flood_pixels, 99):.4f}\")\n",
    "# print(f\"99.9th percentile: {np.percentile(flood_pixels, 99.9):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Define flood mean ranges\n",
    "# value_ranges = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 1.0, np.inf]\n",
    "# range_labels = [f\"≤{r:.3f}\" if r != np.inf else \">1.0\" for r in value_ranges]\n",
    "\n",
    "# def count_samples_by_mean_range(dataset, name=\"train\", max_samples=1000):\n",
    "#     counter = defaultdict(int)\n",
    "#     total = 0\n",
    "\n",
    "#     for i, (_, label) in enumerate(dataset.take(max_samples)):\n",
    "#         label_np = label.numpy()\n",
    "#         label_mean = np.mean(label_np)\n",
    "\n",
    "#         for threshold, label_str in zip(value_ranges, range_labels):\n",
    "#             if label_mean <= threshold:\n",
    "#                 counter[label_str] += 1\n",
    "#                 break\n",
    "#         total += 1\n",
    "\n",
    "#     print(f\"\\n=== {name.capitalize()} Samples by Mean Flood Range (first {total}) ===\")\n",
    "#     for label_str in range_labels:\n",
    "#         count = counter[label_str]\n",
    "#         pct = 100 * count / total if total else 0\n",
    "#         print(f\"{label_str:>6}: {count:>4} samples ({pct:.1f}%)\")\n",
    "#     return counter\n",
    "\n",
    "# # Run this for both datasets\n",
    "# count_samples_by_mean_range(train_dataset, name=\"train\")\n",
    "# count_samples_by_mean_range(validation_dataset, name=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    FloodModel.get_hypermodel(\n",
    "        lstm_units=[128, 64, 32],\n",
    "        lstm_kernel_size=[3, 5],\n",
    "        lstm_dropout=[0.2, 0.3],\n",
    "        lstm_recurrent_dropout=[0.3, 0.2],\n",
    "        n_flood_maps=[5],\n",
    "        m_rainfall=[6],\n",
    "    ),\n",
    "        objective=\"val_loss\",\n",
    "        max_trials=10,\n",
    "        project_name=f\"logs/htune_project_{timestamp}\",\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/htune_project_{timestamp}\"\n",
    "print(log_dir)\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "tuner.search(train_dataset, epochs=50, validation_data=validation_dataset , callbacks=[tb_callback])\n",
    "best_model, best_hp = tuner.get_best_models()[0], tuner.get_best_hyperparameters()[0]\n",
    "best_hp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define final parameters and model\n",
    "final_params = FloodModel.Params(**best_hp.values)\n",
    "model = FloodModel(params=final_params)\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "    ModelCheckpoint(\n",
    "        filepath=log_dir + \"/checkpoint\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_format=\"tf\"\n",
    "    ),\n",
    "    EarlyStopping(               # <--- ADD THIS\n",
    "        monitor=\"val_loss\",       # What to monitor\n",
    "        patience=500,              # Number of epochs with no improvement to wait\n",
    "        restore_best_weights=True, # Restore model weights from best epoch\n",
    "        mode=\"min\"                # \"min\" because lower val_loss is better\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_dataset,\n",
    "    epochs=500,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "model.save_model(log_dir + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test calling the model on some data.\n",
    "# inputs, labels_ = next(iter(train_dataset))\n",
    "# prediction = model.call(inputs)\n",
    "# prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import tensorflow as tf\n",
    "# # Path to your saved model\n",
    "# model_path = \"/home/elhajjas/climateiq-cnn-4/logs/htune_project_20250516-142006/model\"\n",
    "\n",
    "# # Load the model\n",
    "# model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Test calling the model for n predictions\n",
    "# full_dataset = load_dataset(sim_names=sim_names, batch_size=1, dataset_split= \"train\")\n",
    "# inputs, labels = next(iter(full_dataset))\n",
    "# predictions = model.call_n(inputs, n=4)\n",
    "# # predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from usl_models.flood_ml.dataset import load_dataset_windowed\n",
    "from usl_models.flood_ml import constants\n",
    "\n",
    "# # Path to trained model\n",
    "# model_path = \"/home/elhajjas/climateiq-cnn-4/usl_models/notebooks/logs/htune_project_20250508-202940/model\"\n",
    "# model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Number of samples to visualize\n",
    "n_samples = 20\n",
    "\n",
    "# Loop through the dataset and predict\n",
    "for i, (input_data, ground_truth) in enumerate(train_dataset.take(n_samples)):\n",
    "    ground_truth = ground_truth.numpy().squeeze()\n",
    "    prediction = model(input_data).numpy().squeeze()\n",
    "\n",
    "    print(f\"\\nSample {i+1} Prediction Stats:\")\n",
    "    print(\"  Min:\", prediction.min())\n",
    "    print(\"  Max:\", prediction.max())\n",
    "    print(\"  Mean:\", prediction.mean())\n",
    "\n",
    "    # Choose timestep to plot\n",
    "    timestep = 3\n",
    "    gt_t = ground_truth[timestep]\n",
    "    pred_t = prediction[timestep]\n",
    "    vmax_val = max(gt_t.max(), pred_t.max())\n",
    "\n",
    "    # Plot Ground Truth and Prediction\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle(f\"Sample {i+1} - Timestep {timestep}\", fontsize=16)\n",
    "\n",
    "    im1 = axes[0].imshow(gt_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].axis(\"off\")\n",
    "    plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "\n",
    "    im2 = axes[1].imshow(pred_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "    axes[1].axis(\"off\")\n",
    "    plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "# Load your trained model\n",
    "model_path = \"/home/elhajjas/climateiq-cnn-4/usl_models/notebooks/logs/htune_project_20250527-193132/model\"\n",
    "def weighted_mse_small_targets(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom MSE loss that gives higher importance to smaller target values.\n",
    "    Very useful when trying to make the model learn subtle signals like 0.001 depth floods.\n",
    "    \"\"\"\n",
    "    # Ignore NaNs (if any) in labels\n",
    "    mask = tf.math.logical_not(tf.math.is_nan(y_true))\n",
    "    y_true = tf.where(mask, y_true, tf.zeros_like(y_true))\n",
    "    y_pred = tf.where(mask, y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "    # Define inverse-weighting: smaller values get higher weight\n",
    "    weights = 1.0 / (1.0 + 100.0 * y_true)  # e.g., 0.001 -> ~1, 0.1 -> ~0.09\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    weighted_squared_error = weights * squared_error\n",
    "\n",
    "    # Normalize by number of valid entries\n",
    "    return tf.reduce_sum(weighted_squared_error) / tf.reduce_sum(tf.cast(mask, tf.float32))\n",
    "\n",
    "def hybrid_loss(y_true, y_pred):\n",
    "    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
    "    small_weighted = weighted_mse_small_targets(y_true, y_pred)\n",
    "    return 0.5 * mse + 0.5 * small_weighted\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={\"hybrid_loss\": hybrid_loss})\n",
    "\n",
    "\n",
    "# Assuming validation_dataset is already defined\n",
    "# Example:\n",
    "# from usl_models.flood_ml.dataset import load_dataset_windowed\n",
    "# validation_dataset = load_dataset_windowed(...)\n",
    "\n",
    "n_samples = 20\n",
    "timestep = 3\n",
    "metrics_list = []\n",
    "\n",
    "for i, (input_data, ground_truth) in enumerate(validation_dataset.take(n_samples)):\n",
    "    ground_truth = ground_truth.numpy().squeeze()\n",
    "    prediction = model(input_data).numpy().squeeze()\n",
    "\n",
    "    gt_t = ground_truth[timestep]\n",
    "    pred_t = prediction[timestep]\n",
    "    vmax_val = np.nanpercentile([gt_t, pred_t], 99.5)\n",
    "\n",
    "    # Mask out NaNs\n",
    "    mask = ~np.isnan(gt_t)\n",
    "    gt_flat = gt_t[mask].flatten()\n",
    "    pred_flat = pred_t[mask].flatten()\n",
    "\n",
    "    mae = mean_absolute_error(gt_flat, pred_flat)\n",
    "    rmse = np.sqrt(mean_squared_error(gt_flat, pred_flat))\n",
    "    bias = np.mean(pred_flat) - np.mean(gt_flat)\n",
    "    iou = np.logical_and(gt_flat > 0.1, pred_flat > 0.1).sum() / max(1, np.logical_or(gt_flat > 0.1, pred_flat > 0.1).sum())\n",
    "    ssim_val = ssim(gt_t, pred_t, data_range=gt_t.max() - gt_t.min())\n",
    "\n",
    "    metrics_list.append({\n",
    "        \"Sample\": i+1,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Bias\": bias,\n",
    "        \"IoU > 0.1\": iou,\n",
    "        \"SSIM\": ssim_val\n",
    "    })\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle(f\"Sample {i+1} - Timestep {timestep}\", fontsize=16)\n",
    "\n",
    "    im1 = axes[0].imshow(gt_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].axis(\"off\")\n",
    "    plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "\n",
    "    im2 = axes[1].imshow(pred_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "    axes[1].axis(\"off\")\n",
    "    plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(metrics_list)\n",
    "print(\"\\n=== Metrics Summary ===\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "# === Custom loss ===\n",
    "def weighted_mse_small_targets(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom MSE loss that gives higher weight to small target values.\n",
    "    Emphasizes learning small flood depths like 0.001–0.03 more than high values.\n",
    "    \"\"\"\n",
    "    weights = 1.0 / (1.0 + tf.square(y_true * 10))  # Scale emphasis on smaller targets\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    weighted_error = weights * squared_error\n",
    "    return tf.reduce_mean(weighted_error)\n",
    "\n",
    "# === Load all models ===\n",
    "model_paths = {\n",
    "    \"Baseline\": \"/home/elhajjas/climateiq-cnn-4/logs/baselineManhattan50epochs20tuner/model\",\n",
    "    \"Attentionafterconvlstm\": \"logs/htune_project_20250522-150650/model\",\n",
    "    \"Attentionbeforeandafterconvlstm\": \"/home/elhajjas/climateiq-cnn-4/usl_models/notebooks/logs/attentionbeforeandafterconvlstm50epochsjustManh/model\"\n",
    "}\n",
    "\n",
    "models = {\n",
    "    name: tf.keras.models.load_model(path, custom_objects={\"weighted_mse_small_targets\": weighted_mse_small_targets})\n",
    "    for name, path in model_paths.items()\n",
    "}\n",
    "\n",
    "# === Evaluation setup ===\n",
    "n_samples = 20\n",
    "timestep = 3\n",
    "metrics_list = []\n",
    "\n",
    "# Loop through validation data (adjust this to your dataset)\n",
    "for i, (input_data, ground_truth) in enumerate(validation_dataset.take(n_samples)):\n",
    "    ground_truth = ground_truth.numpy().squeeze()\n",
    "    model_preds = {name: model(input_data).numpy().squeeze() for name, model in models.items()}\n",
    "    \n",
    "    gt_t = ground_truth[timestep]\n",
    "    vmax_val = np.nanpercentile([gt_t] + [pred[timestep] for pred in model_preds.values()], 99.5)\n",
    "    mask = ~np.isnan(gt_t)\n",
    "    gt_flat = gt_t[mask].flatten()\n",
    "\n",
    "    sample_metrics = {\"Sample\": i+1}\n",
    "\n",
    "    # === Visualization ===\n",
    "    fig, axes = plt.subplots(1, len(models) + 1, figsize=(7 * (len(models) + 1), 6))\n",
    "    fig.suptitle(f\"Sample {i+1} - Timestep {timestep}\", fontsize=16)\n",
    "\n",
    "    im = axes[0].imshow(gt_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].axis(\"off\")\n",
    "    plt.colorbar(im, ax=axes[0], shrink=0.8)\n",
    "\n",
    "    for j, (name, pred) in enumerate(model_preds.items(), 1):\n",
    "        pred_t = pred[timestep]\n",
    "        pred_flat = pred_t[mask].flatten()\n",
    "\n",
    "        sample_metrics[f\"{name} MAE\"] = mean_absolute_error(gt_flat, pred_flat)\n",
    "        sample_metrics[f\"{name} RMSE\"] = np.sqrt(mean_squared_error(gt_flat, pred_flat))\n",
    "        sample_metrics[f\"{name} Bias\"] = np.mean(pred_flat) - np.mean(gt_flat)\n",
    "        sample_metrics[f\"{name} IoU > 0.1\"] = np.logical_and(gt_flat > 0.1, pred_flat > 0.1).sum() / max(\n",
    "            1, np.logical_or(gt_flat > 0.1, pred_flat > 0.1).sum())\n",
    "        sample_metrics[f\"{name} SSIM\"] = ssim(gt_t, pred_t, data_range=gt_t.max() - gt_t.min())\n",
    "\n",
    "        im = axes[j].imshow(pred_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "        axes[j].set_title(f\"{name} Prediction\")\n",
    "        axes[j].axis(\"off\")\n",
    "        plt.colorbar(im, ax=axes[j], shrink=0.8)\n",
    "\n",
    "    metrics_list.append(sample_metrics)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Summary ===\n",
    "df = pd.DataFrame(metrics_list)\n",
    "print(\"\\n=== Metrics Summary ===\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "# Load your trained model\n",
    "model_path = \"/home/elhajjas/climateiq-cnn-4/logs/baselineManhattan50epochs20tuner/model\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Assuming validation_dataset is already defined\n",
    "# Example:\n",
    "# from usl_models.flood_ml.dataset import load_dataset_windowed\n",
    "# validation_dataset = load_dataset_windowed(...)\n",
    "\n",
    "n_samples = 20\n",
    "timestep = 3\n",
    "metrics_list = []\n",
    "\n",
    "for i, (input_data, ground_truth) in enumerate(validation_dataset.take(n_samples)):\n",
    "    ground_truth = ground_truth.numpy().squeeze()\n",
    "    prediction = model(input_data).numpy().squeeze()\n",
    "\n",
    "    gt_t = ground_truth[timestep]\n",
    "    pred_t = prediction[timestep]\n",
    "    vmax_val = np.nanpercentile([gt_t, pred_t], 99.5)\n",
    "\n",
    "    # Mask out NaNs\n",
    "    mask = ~np.isnan(gt_t)\n",
    "    gt_flat = gt_t[mask].flatten()\n",
    "    pred_flat = pred_t[mask].flatten()\n",
    "\n",
    "    mae = mean_absolute_error(gt_flat, pred_flat)\n",
    "    rmse = np.sqrt(mean_squared_error(gt_flat, pred_flat))\n",
    "    bias = np.mean(pred_flat) - np.mean(gt_flat)\n",
    "    iou = np.logical_and(gt_flat > 0.1, pred_flat > 0.1).sum() / max(1, np.logical_or(gt_flat > 0.1, pred_flat > 0.1).sum())\n",
    "    ssim_val = ssim(gt_t, pred_t, data_range=gt_t.max() - gt_t.min())\n",
    "\n",
    "    metrics_list.append({\n",
    "        \"Sample\": i+1,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Bias\": bias,\n",
    "        \"IoU > 0.1\": iou,\n",
    "        \"SSIM\": ssim_val\n",
    "    })\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle(f\"Sample {i+1} - Timestep {timestep}\", fontsize=16)\n",
    "\n",
    "    im1 = axes[0].imshow(gt_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].axis(\"off\")\n",
    "    plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "\n",
    "    im2 = axes[1].imshow(pred_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "    axes[1].axis(\"off\")\n",
    "    plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(metrics_list)\n",
    "print(\"\\n=== Metrics Summary ===\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "# Load all models\n",
    "model_paths = {\n",
    "    \"Baseline\": \"/home/elhajjas/climateiq-cnn-4/logs/baselineManhattan50epochs20tuner/model\",\n",
    "    \"Attentionafterconvlstm\": \"logs/htune_project_20250522-150650/model\",\n",
    "    \"Attentionbeforeandafterconvlstm\": \"/home/elhajjas/climateiq-cnn-4/usl_models/notebooks/logs/attentionbeforeandafterconvlstm50epochsjustManh/model\"\n",
    "}\n",
    "models = {name: tf.keras.models.load_model(path) for name, path in model_paths.items()}\n",
    "\n",
    "# Adjust as needed for your dataset\n",
    "n_samples = 20\n",
    "timestep = 3\n",
    "metrics_list = []\n",
    "\n",
    "for i, (input_data, ground_truth) in enumerate(train_dataset.take(n_samples)):\n",
    "    ground_truth = ground_truth.numpy().squeeze()\n",
    "    model_preds = {name: model(input_data).numpy().squeeze() for name, model in models.items()}\n",
    "    \n",
    "    gt_t = ground_truth[timestep]\n",
    "    vmax_val = np.nanpercentile([gt_t] + [pred[timestep] for pred in model_preds.values()], 99.5)\n",
    "    mask = ~np.isnan(gt_t)\n",
    "    gt_flat = gt_t[mask].flatten()\n",
    "    \n",
    "    sample_metrics = {\"Sample\": i + 1}\n",
    "    fig, axes = plt.subplots(1, len(models) + 1, figsize=(7 * (len(models) + 1), 6))\n",
    "    fig.suptitle(f\"Sample {i+1} - Timestep {timestep}\", fontsize=16)\n",
    "\n",
    "    im = axes[0].imshow(gt_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].axis(\"off\")\n",
    "    plt.colorbar(im, ax=axes[0], shrink=0.8)\n",
    "\n",
    "    for j, (name, pred) in enumerate(model_preds.items(), 1):\n",
    "        pred_t = pred[timestep]\n",
    "        pred_flat = pred_t[mask].flatten()\n",
    "\n",
    "        sample_metrics[f\"{name} MAE\"] = mean_absolute_error(gt_flat, pred_flat)\n",
    "        sample_metrics[f\"{name} RMSE\"] = np.sqrt(mean_squared_error(gt_flat, pred_flat))\n",
    "        sample_metrics[f\"{name} Bias\"] = np.mean(pred_flat) - np.mean(gt_flat)\n",
    "        sample_metrics[f\"{name} IoU > 0.1\"] = np.logical_and(gt_flat > 0.1, pred_flat > 0.1).sum() / max(\n",
    "            1, np.logical_or(gt_flat > 0.1, pred_flat > 0.1).sum())\n",
    "        sample_metrics[f\"{name} SSIM\"] = ssim(gt_t, pred_t, data_range=gt_t.max() - gt_t.min())\n",
    "\n",
    "        im = axes[j].imshow(pred_t, cmap=\"Blues\", vmin=0, vmax=vmax_val)\n",
    "        axes[j].set_title(f\"{name} Prediction\")\n",
    "        axes[j].axis(\"off\")\n",
    "        plt.colorbar(im, ax=axes[j], shrink=0.8)\n",
    "\n",
    "    metrics_list.append(sample_metrics)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create DataFrame and plot errors\n",
    "# df = pd.DataFrame(metrics_list)\n",
    "# df_plot = df.set_index(\"Sample\")[[col for col in df.columns if \"RMSE\" in col or \"MAE\" in col]]\n",
    "# df_plot.plot(kind=\"bar\", figsize=(18, 6), title=\"RMSE and MAE by Model per Sample\")\n",
    "# plt.ylabel(\"Error Value\")\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "# === Custom loss ===\n",
    "def weighted_mse_small_targets(y_true, y_pred):\n",
    "    weights = 1.0 / (1.0 + tf.square(y_true * 10))\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    weighted_error = weights * squared_error\n",
    "    return tf.reduce_mean(weighted_error)\n",
    "\n",
    "# === Paths for comparison ===\n",
    "model_paths = {\n",
    "    \"Baseline\": \"/home/elhajjas/climateiq-cnn-4/logs/baselineManhattan50epochs20tuner/model\",\n",
    "    \"Attentionafterconvlstm\": \"logs/htune_project_20250522-150650/model\",\n",
    "    \"Attentionbeforeandafterconvlstm\": \"/home/elhajjas/climateiq-cnn-4/usl_models/notebooks/logs/attentionbeforeandafterconvlstm50epochsjustManh/model\"\n",
    "}\n",
    "\n",
    "# === Evaluation setup ===\n",
    "n_samples = 20\n",
    "timestep = 3\n",
    "metrics_list = []\n",
    "\n",
    "for i, (input_data, ground_truth) in enumerate(validation_dataset.take(n_samples)):\n",
    "    ground_truth = ground_truth.numpy().squeeze()\n",
    "    gt_t = ground_truth[timestep]\n",
    "    mask = ~np.isnan(gt_t)\n",
    "    gt_flat = gt_t[mask].flatten()\n",
    "\n",
    "    sample_metrics = {\"Sample\": i + 1}\n",
    "    preds = {}\n",
    "\n",
    "    # Plot ground truth\n",
    "    fig, axes = plt.subplots(1, len(model_paths) + 1, figsize=(7 * (len(model_paths) + 1), 6))\n",
    "    fig.suptitle(f\"Sample {i + 1} - Timestep {timestep}\", fontsize=16)\n",
    "\n",
    "    im = axes[0].imshow(gt_t, cmap=\"Blues\")\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].axis(\"off\")\n",
    "    plt.colorbar(im, ax=axes[0], shrink=0.8)\n",
    "\n",
    "    # Run predictions one-by-one to avoid OOM\n",
    "    for j, (name, path) in enumerate(model_paths.items(), 1):\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = tf.keras.models.load_model(path, custom_objects={\"weighted_mse_small_targets\": weighted_mse_small_targets})\n",
    "        prediction = model(input_data).numpy().squeeze()\n",
    "        pred_t = prediction[timestep]\n",
    "        pred_flat = pred_t[mask].flatten()\n",
    "\n",
    "        sample_metrics[f\"{name} MAE\"] = mean_absolute_error(gt_flat, pred_flat)\n",
    "        sample_metrics[f\"{name} RMSE\"] = np.sqrt(mean_squared_error(gt_flat, pred_flat))\n",
    "        sample_metrics[f\"{name} Bias\"] = np.mean(pred_flat) - np.mean(gt_flat)\n",
    "        sample_metrics[f\"{name} IoU > 0.1\"] = np.logical_and(gt_flat > 0.1, pred_flat > 0.1).sum() / max(\n",
    "            1, np.logical_or(gt_flat > 0.1, pred_flat > 0.1).sum())\n",
    "        sample_metrics[f\"{name} SSIM\"] = ssim(gt_t, pred_t, data_range=gt_t.max() - gt_t.min())\n",
    "\n",
    "        preds[name] = pred_t\n",
    "        im = axes[j].imshow(pred_t, cmap=\"Blues\", vmin=0, vmax=np.nanpercentile([gt_t] + list(preds.values()), 99.5))\n",
    "        axes[j].set_title(f\"{name} Prediction\")\n",
    "        axes[j].axis(\"off\")\n",
    "        plt.colorbar(im, ax=axes[j], shrink=0.8)\n",
    "\n",
    "    metrics_list.append(sample_metrics)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Summary ===\n",
    "df = pd.DataFrame(metrics_list)\n",
    "print(\"\\n=== Metrics Summary ===\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Convert long-form for Seaborn\n",
    "metric_names = [\"MAE\", \"RMSE\", \"Bias\", \"IoU > 0.1\", \"SSIM\"]\n",
    "model_names = [\"Baseline\", \"Attention\"]\n",
    "\n",
    "for metric in [\"RMSE\", \"MAE\"]:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model in model_names:\n",
    "        sns.lineplot(data=df, x=\"Sample\", y=f\"{model} {metric}\", label=f\"{model} {metric}\", marker=\"o\")\n",
    "\n",
    "    plt.title(f\"{metric} Across Samples\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df.melt(id_vars=[\"Sample\"], value_vars=[f\"{m} RMSE\" for m in model_names],\n",
    "                    var_name=\"Model\", value_name=\"RMSE\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_melted, x=\"Sample\", y=\"RMSE\", hue=\"Model\")\n",
    "plt.title(\"RMSE by Sample for Each Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
