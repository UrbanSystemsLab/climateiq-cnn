{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atmo Model Training Notebook\n",
    "\n",
    "Train an Atmo Model using `usl_models` lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:33:12.864102: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-02 19:33:12.914061: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-02 19:33:12.914096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-02 19:33:12.915302: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 19:33:12.923184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "from usl_models.atmo_ml.model import AtmoModel, AtmoModelParams\n",
    "from usl_models.atmo_ml import dataset\n",
    "from google.cloud import storage\n",
    "\n",
    "# climateiq-study-area-feature-chunks/NYC_Heat/NYC_summer_2000_01p\n",
    "# Define bucket names and folder paths\n",
    "data_bucket_name = \"climateiq-study-area-feature-chunks\"\n",
    "label_bucket_name = \"climateiq-study-area-label-chunks\"\n",
    "sim_names = [\"NYC_Heat_Test/NYC_summer_2000_01p\"]\n",
    "time_steps_per_day = 6\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:33:15.579561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
      "2024-12-02 19:33:27.845595: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\n",
      "\n",
      "\n",
      "2024-12-02 19:33:27.865223: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m ds \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mload_dataset(\n\u001b[1;32m      4\u001b[0m     data_bucket_name\u001b[38;5;241m=\u001b[39mdata_bucket_name,\n\u001b[1;32m      5\u001b[0m     label_bucket_name\u001b[38;5;241m=\u001b[39mlabel_bucket_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     max_blobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mbatch(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/climateiq-cnn/usl_models/usl_models/atmo_ml/dataset.py:272\u001b[0m, in \u001b[0;36msplit_dataset\u001b[0;34m(dataset, train_frac, val_frac, test_frac)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Splits a tf.data.Dataset into training, validation, and test sets.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    train, validation, and test data.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m train_frac \u001b[38;5;241m+\u001b[39m val_frac \u001b[38;5;241m+\u001b[39m test_frac \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFractions must sum to 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 272\u001b[0m total_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calculate the total dataset size\u001b[39;00m\n\u001b[1;32m    273\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(train_frac \u001b[38;5;241m*\u001b[39m total_size)\n\u001b[1;32m    274\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(val_frac \u001b[38;5;241m*\u001b[39m total_size)\n",
      "File \u001b[0;32m~/climateiq-cnn/usl_models/usl_models/atmo_ml/dataset.py:272\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Splits a tf.data.Dataset into training, validation, and test sets.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    train, validation, and test data.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m train_frac \u001b[38;5;241m+\u001b[39m val_frac \u001b[38;5;241m+\u001b[39m test_frac \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFractions must sum to 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 272\u001b[0m total_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calculate the total dataset size\u001b[39;00m\n\u001b[1;32m    273\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(train_frac \u001b[38;5;241m*\u001b[39m total_size)\n\u001b[1;32m    274\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(val_frac \u001b[38;5;241m*\u001b[39m total_size)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (1, 200, 200, 22) where an element of shape (200, 200, 22) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# Create the training dataset using create_atmo_dataset with sim_names\n",
    "client = storage.Client(project=\"climateiq\")\n",
    "ds = dataset.load_dataset(\n",
    "    data_bucket_name=data_bucket_name,\n",
    "    label_bucket_name=label_bucket_name,\n",
    "    sim_names=sim_names,\n",
    "    timesteps_per_day=time_steps_per_day,\n",
    "    max_blobs=30,\n",
    ")\n",
    "ds = ds.batch(batch_size=4)\n",
    "train_dataset, val_dataset, test_dataset = dataset.split_dataset(\n",
    "    ds, train_frac=0.7, val_frac=0.15, test_frac=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Atmo Model\n",
    "model_params = AtmoModelParams()\n",
    "model = AtmoModel(model_params)\n",
    "# model._model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lu_index_input (None, 200, 200)\n",
      "lu_index_embedded_flat Tensor(\"atmo_conv_lstm_10/embedding_10/embedding_lookup/Identity:0\", shape=(None, 40000, 8), dtype=float32)\n",
      "lu_index_embedded (None, 200, 200, 8)\n",
      "spatial_cnn_output (None, 6, 50, 50, 128)\n",
      "lstm_output (None, 5, 50, 50, 512)\n",
      "permutedshape (None, 50, 50, 5, 512)\n",
      "trconv_input (None, 8, 50, 50, 256)\n",
      "outputs[0] (None, 8, 200, 200, 1)\n",
      "lu_index_input (None, 200, 200)\n",
      "lu_index_embedded_flat Tensor(\"atmo_conv_lstm_10/embedding_10/embedding_lookup/Identity:0\", shape=(None, 40000, 8), dtype=float32)\n",
      "lu_index_embedded (None, 200, 200, 8)\n",
      "spatial_cnn_output (None, 6, 50, 50, 128)\n",
      "lstm_output (None, 5, 50, 50, 512)\n",
      "permutedshape (None, 50, 50, 5, 512)\n",
      "trconv_input (None, 8, 50, 50, 256)\n",
      "outputs[0] (None, 8, 200, 200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 20:19:31.242676: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inatmo_conv_lstm_10/conv_lstm/conv_lstm2d_10/while/body/_1/atmo_conv_lstm_10/conv_lstm/conv_lstm2d_10/while/dropout_7/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-11-21 20:19:32.134690: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 16365553684496521654\n",
      "2024-11-21 20:19:32.134736: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 7210658781760474270\n",
      "2024-11-21 20:19:32.134742: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 15804210494231023062\n",
      "2024-11-21 20:19:32.134747: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 2249478919593754292\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node atmo_conv_lstm_10/Reshape_2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/opt/conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/tmp/ipykernel_9509/1633930797.py\", line 2, in <module>\n\n  File \"/home/elhajjas/climateiq-cnn-6/usl_models/usl_models/atmo_ml/model.py\", line 126, in fit\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/elhajjas/climateiq-cnn-6/usl_models/usl_models/atmo_ml/model.py\", line 463, in call\n\n  File \"/home/elhajjas/climateiq-cnn-6/usl_models/usl_models/atmo_ml/data_utils.py\", line 68, in split_time_step_pairs\n\nInput to reshape is a tensor with 25600000 values, but the requested shape has 20480000\n\t [[{{node atmo_conv_lstm_10/Reshape_2}}]] [Op:__inference_train_function_97587]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/climateiq-cnn-6/usl_models/usl_models/atmo_ml/model.py:126\u001b[0m, in \u001b[0;36mAtmoModel.fit\u001b[0;34m(self, train_dataset, val_dataset, epochs, steps_per_epoch, early_stopping, callbacks)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m early_stopping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    121\u001b[0m         keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m    122\u001b[0m             monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39mearly_stopping\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node atmo_conv_lstm_10/Reshape_2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/opt/conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/tmp/ipykernel_9509/1633930797.py\", line 2, in <module>\n\n  File \"/home/elhajjas/climateiq-cnn-6/usl_models/usl_models/atmo_ml/model.py\", line 126, in fit\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/elhajjas/climateiq-cnn-6/usl_models/usl_models/atmo_ml/model.py\", line 463, in call\n\n  File \"/home/elhajjas/climateiq-cnn-6/usl_models/usl_models/atmo_ml/data_utils.py\", line 68, in split_time_step_pairs\n\nInput to reshape is a tensor with 25600000 values, but the requested shape has 20480000\n\t [[{{node atmo_conv_lstm_10/Reshape_2}}]] [Op:__inference_train_function_97587]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spatiotemporal': TensorShape([2, 6, 200, 200, 12]),\n",
       " 'spatial': TensorShape([2, 200, 200, 22]),\n",
       " 'lu_index': TensorShape([2, 200, 200])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(iter(train_dataset))\n",
    "{key: tensor.shape for key, tensor in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"atmo_conv_lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  488       \n",
      "                                                                 \n",
      " spatial_cnn (Sequential)    (None, 50, 50, 128)       252992    \n",
      "                                                                 \n",
      " spatiotemporal_cnn (Sequen  (None, None, 50, 50, 64   30480     \n",
      " tial)                       )                                   \n",
      "                                                                 \n",
      " conv_lstm (Sequential)      (None, None, 50, 50, 51   45877248  \n",
      "                             2)                                  \n",
      "                                                                 \n",
      " t2_output_cnn (Sequential)  (None, None, 200, 200,    69729     \n",
      "                             1)                                  \n",
      "                                                                 \n",
      " rh2_output_cnn (Sequential  (None, None, 200, 200,    69729     \n",
      " )                           1)                                  \n",
      "                                                                 \n",
      " wspd10_output_cnn (Sequent  (None, None, 200, 200,    69729     \n",
      " ial)                        1)                                  \n",
      "                                                                 \n",
      " wdir10_output_cnn (Sequent  (None, None, 200, 200,    69746     \n",
      " ial)                        2)                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46440141 (177.16 MB)\n",
      "Trainable params: 46440141 (177.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model._model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lu_index_input (2, 200, 200)\n",
      "lu_index_embedded_flat tf.Tensor(\n",
      "[[[-0.0290212  -0.00429965  0.0070921  ...  0.04053745 -0.02890884\n",
      "    0.00442706]\n",
      "  [ 0.04117144  0.03346105  0.00490087 ...  0.01888017  0.02810446\n",
      "    0.0290962 ]\n",
      "  [ 0.01980658  0.01989866 -0.02752843 ...  0.02466523  0.03207915\n",
      "    0.01597965]\n",
      "  ...\n",
      "  [ 0.04117144  0.03346105  0.00490087 ...  0.01888017  0.02810446\n",
      "    0.0290962 ]\n",
      "  [-0.00921012  0.02187858 -0.02844076 ...  0.04788701  0.01579146\n",
      "   -0.04698772]\n",
      "  [-0.00921012  0.02187858 -0.02844076 ...  0.04788701  0.01579146\n",
      "   -0.04698772]]\n",
      "\n",
      " [[-0.0290212  -0.00429965  0.0070921  ...  0.04053745 -0.02890884\n",
      "    0.00442706]\n",
      "  [ 0.04117144  0.03346105  0.00490087 ...  0.01888017  0.02810446\n",
      "    0.0290962 ]\n",
      "  [ 0.01980658  0.01989866 -0.02752843 ...  0.02466523  0.03207915\n",
      "    0.01597965]\n",
      "  ...\n",
      "  [ 0.04117144  0.03346105  0.00490087 ...  0.01888017  0.02810446\n",
      "    0.0290962 ]\n",
      "  [-0.00921012  0.02187858 -0.02844076 ...  0.04788701  0.01579146\n",
      "   -0.04698772]\n",
      "  [-0.00921012  0.02187858 -0.02844076 ...  0.04788701  0.01579146\n",
      "   -0.04698772]]], shape=(2, 40000, 8), dtype=float32)\n",
      "lu_index_embedded (2, 200, 200, 8)\n",
      "spatial_cnn_output (2, 6, 50, 50, 128)\n",
      "lstm_output (2, 5, 50, 50, 512)\n",
      "permutedshape TensorShape([2, 50, 50, 5, 512])\n",
      "desired_time_steps 8\n",
      "trconv_input (2, 8, 50, 50, 256)\n",
      "outputs[0] (2, 8, 200, 200, 1)\n",
      "Prediction shape: (2, 8, 200, 200, 5)\n"
     ]
    }
   ],
   "source": [
    "# Test calling the model on some training data\n",
    "inputs, labels = next(iter(train_dataset))\n",
    "prediction = model.call(inputs)\n",
    "print(\"Prediction shape:\", prediction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
