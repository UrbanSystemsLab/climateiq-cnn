{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Atmo Model Training Notebook\n",
            "\n",
            "Train an Atmo Model using `usl_models` lib."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "%load_ext autoreload\n",
            "%autoreload 2\n",
            "import tensorflow as tf\n",
            "import keras\n",
            "import os, time\n",
            "import pathlib\n",
            "from usl_models.atmo_ml.model import AtmoModel, AtmoModelParams\n",
            "from usl_models.atmo_ml import dataset, visualizer, vars\n",
            "\n",
            "import logging\n",
            "\n",
            "logging.getLogger().setLevel(logging.INFO)\n",
            "\n",
            "# climateiq-study-area-feature-chunks/NYC_Heat/NYC_summer_2000_01p\n",
            "time_steps_per_day = 6\n",
            "batch_size = 2\n",
            "\n",
            "sim_dirs = [\n",
            "    (\n",
            "        \"NYC_Heat_Test\",\n",
            "        [\n",
            "            \"NYC_summer_2000_01p\",\n",
            "            # 'NYC_summer_2010_99p',\n",
            "            # 'NYC_summer_2015_50p',\n",
            "            # 'NYC_summer_2017_25p',\n",
            "            # 'NYC_summer_2018_75p'\n",
            "        ],\n",
            "    ),\n",
            "    (\n",
            "        \"PHX_Heat_Test\",\n",
            "        [\n",
            "            # 'PHX_summer_2008_25p',\n",
            "            # 'PHX_summer_2009_50p',\n",
            "            # 'PHX_summer_2011_99p',\n",
            "            # 'PHX_summer_2015_75p',\n",
            "            # 'PHX_summer_2020_01p'\n",
            "        ],\n",
            "    ),\n",
            "]\n",
            "\n",
            "sim_names = []\n",
            "for sim_dir, subdirs in sim_dirs:\n",
            "    for subdir in subdirs:\n",
            "        sim_names.append(sim_dir + \"/\" + subdir)\n",
            "\n",
            "print(sim_names)\n",
            "\n",
            "\n",
            "output_vars = [\n",
            "    vars.SpatiotemporalOutput.RH2\n",
            "]\n",
            "\n",
            "filecache_path = pathlib.Path(\"/home/shared/climateiq/filecache\")\n",
            "\n",
            "example_keys=[\n",
            "    (\"NYC_Heat_Test/NYC_summer_2000_01p\", \"2000-05-25\"),\n",
            "    (\"NYC_Heat_Test/NYC_summer_2000_01p\", \"2000-05-26\"),\n",
            "    (\"NYC_Heat_Test/NYC_summer_2000_01p\", \"2000-05-27\"),\n",
            "    (\"NYC_Heat_Test/NYC_summer_2000_01p\", \"2000-05-28\")\n",
            "]\n",
            "\n",
            "train_frac = 0.8\n",
            "train_ds = dataset.load_dataset_cached(\n",
            "    filecache_path,\n",
            "    output_vars=output_vars,\n",
            "    example_keys=example_keys\n",
            ").batch(batch_size=batch_size)\n",
            "val_ds = dataset.load_dataset_cached(\n",
            "    filecache_path,\n",
            "    output_vars=output_vars,\n",
            "    example_keys=example_keys\n",
            ").batch(batch_size=batch_size)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Initialize the Atmo Model\n",
            "model_params = AtmoModelParams(output_vars=output_vars)\n",
            "model = AtmoModel(model_params)\n",
            "model.summary(expand_nested=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Train the model\n",
            "# Create a unique log directory by appending the current timestamp\n",
            "log_dir = os.path.join(\"./logs\", \"run_\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
            "print(log_dir)\n",
            "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
            "model.fit(train_ds, val_ds, epochs=50, callbacks=[tb_callback], validation_freq=10)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "visualizer.init_plt()\n",
            "\n",
            "for input_batch, label_batch in val_ds:\n",
            "    preds = model.call(input_batch)\n",
            "    for b, _ in enumerate(label_batch):\n",
            "        figs = visualizer.plot(\n",
            "            inputs={k: v[b] for k, v in input_batch.items()},\n",
            "            label=tf.expand_dims(label_batch[b], axis=0),\n",
            "            pred=tf.expand_dims(preds[b], axis=0),\n",
            "            st_var=vars.Spatiotemporal.RH,\n",
            "            sto_var=vars.SpatiotemporalOutput.RH2,\n",
            "        )\n",
            "        for fig in figs:\n",
            "            fig.show()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.9"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
