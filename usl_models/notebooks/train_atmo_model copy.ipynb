{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atmo Model Training Notebook\n",
    "\n",
    "Train an Atmo Model using `usl_models` lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:07:33.968282: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-21 17:07:34.016792: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-21 17:07:34.016823: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-21 17:07:34.018018: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-21 17:07:34.025353: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NYC_Heat_Test/NYC_summer_2000_01p', 'PHX_Heat_Test/PHX_summer_2008_25p']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from usl_models.atmo_ml.model import AtmoModel, AtmoModelParams\n",
    "from usl_models.atmo_ml import dataset\n",
    "from google.cloud import storage\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# climateiq-study-area-feature-chunks/NYC_Heat/NYC_summer_2000_01p\n",
    "# Define bucket names and folder paths\n",
    "data_bucket_name = \"climateiq-study-area-feature-chunks\"\n",
    "label_bucket_name = \"climateiq-study-area-label-chunks\"\n",
    "time_steps_per_day = 6\n",
    "batch_size = 2\n",
    "\n",
    "sim_dirs = [\n",
    "    ('NYC_Heat_Test', [\n",
    "        'NYC_summer_2000_01p',\n",
    "        # 'NYC_summer_2010_99p',\n",
    "        # 'NYC_summer_2015_50p',\n",
    "        # 'NYC_summer_2017_25p',\n",
    "        # 'NYC_summer_2018_75p'\n",
    "    ]),\n",
    "    ('PHX_Heat_Test', [\n",
    "        'PHX_summer_2008_25p',\n",
    "        # 'PHX_summer_2009_50p',\n",
    "        # 'PHX_summer_2011_99p',\n",
    "        # 'PHX_summer_2015_75p',\n",
    "        # 'PHX_summer_2020_01p'\n",
    "    ])\n",
    "]\n",
    "\n",
    "sim_names = []\n",
    "for sim_dir, subdirs in sim_dirs:\n",
    "    for subdir in subdirs:\n",
    "        sim_names.append(sim_dir + '/' + subdir)\n",
    "\n",
    "print(sim_names)\n",
    "client = storage.Client(project=\"climateiq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Total simulation days before filtering: 200\n",
      "2025-01-21 17:07:45.212826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 886 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
      "INFO:root:Total simulation days before filtering: 200\n"
     ]
    }
   ],
   "source": [
    "train_frac = 0.8\n",
    "\n",
    "# Create training dataset with fused spatiotemporal data\n",
    "train_ds = dataset.load_fake_dataset(\n",
    "    data_bucket_name=data_bucket_name,\n",
    "    label_bucket_name=label_bucket_name,\n",
    "    sim_names=sim_names,\n",
    ").batch(batch_size=batch_size)\n",
    "\n",
    "# Create validation dataset with fused spatiotemporal data\n",
    "val_ds = dataset.load_fake_dataset(\n",
    "    data_bucket_name=data_bucket_name,\n",
    "    label_bucket_name=label_bucket_name,\n",
    "    sim_names=sim_names,\n",
    ").batch(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.8\n",
    "\n",
    "# Create training dataset with fused spatiotemporal data\n",
    "train_ds = dataset.load_dataset(\n",
    "    data_bucket_name=data_bucket_name,\n",
    "    label_bucket_name=label_bucket_name,\n",
    "    sim_names=sim_names,\n",
    "    hash_range=(0.0, train_frac),\n",
    ").batch(batch_size=batch_size)\n",
    "\n",
    "# Create validation dataset with fused spatiotemporal data\n",
    "val_ds = dataset.load_dataset(\n",
    "    data_bucket_name=data_bucket_name,\n",
    "    label_bucket_name=label_bucket_name,\n",
    "    sim_names=sim_names,\n",
    "    hash_range=(train_frac, 1.0),\n",
    ").batch(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 0\n",
    "for batch in train_ds:\n",
    "    num_samples += batch[0]['spatiotemporal'].shape[0]\n",
    "print(\"Number of samples:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 0\n",
    "for batch in val_ds:\n",
    "    num_samples += batch[0]['spatiotemporal'].shape[0]\n",
    "print(\"Number of samples:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Atmo Model\n",
    "model_params = AtmoModelParams()\n",
    "model = AtmoModel(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique log directory by appending the current timestamp\n",
    "log_dir = os.path.join(\"./logs\", \"run_\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# Set up TensorBoard callback\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit( train_ds, val_ds, epochs=500, callbacks=[tb_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._model.save(\"saved_model/atmo_model2\", save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model(\"saved_model/atmo_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions from the validation set\n",
    "predictions = model._model.predict(val_ds)  # Use the underlying Keras model\n",
    "\n",
    "# Assuming the structure of val_ds returns (input_data, ground_truth)\n",
    "for input_data, ground_truth in val_ds.take(1):  # Taking just one batch from val_ds\n",
    "    # Get predicted labels\n",
    "    predicted_labels = model._model.predict(input_data)\n",
    "    \n",
    "    # Visualize the first sample\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Ground Truth Visualization\n",
    "    axes[0].imshow(ground_truth[0,:, :, :, 0], cmap='viridis')  # Adjust if output shape differs\n",
    "    axes[0].set_title('Ground Truth')\n",
    "\n",
    "    # Prediction Visualization\n",
    "    axes[1].imshow(predicted_labels[0, :,:, :, 0], cmap='viridis')  # Adjust if output shape differs\n",
    "    axes[1].set_title('Predicted Labels')\n",
    "\n",
    "    plt.show()\n",
    "    break  # Break after visualizing one batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels.shape\n",
    "ground_truth[0, :, :, :].shape\n",
    "predicted_labels[0, :, :, :].shape\n",
    "ground_truth[0, 0, :, :, channel_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first image in the batch\n",
    "sample_index = 14  # Index of the sample in the batch\n",
    "channel_index = 1  # Select the first channel to visualize\n",
    "\n",
    "# Extract data for visualization\n",
    "ground_truth_image = ground_truth[sample_index, 0, :, :, channel_index]  # Shape: (200, 200)\n",
    "predicted_image = predicted_labels[sample_index,0,  :, :, channel_index]  # Shape: (200, 200)\n",
    "\n",
    "# Visualize the ground truth and predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Ground Truth Visualization\n",
    "axes[0].imshow(ground_truth_image, cmap='viridis')\n",
    "axes[0].set_title('Ground Truth (Channel 0)')\n",
    "\n",
    "# Prediction Visualization\n",
    "axes[1].imshow(predicted_image, cmap='viridis')\n",
    "axes[1].set_title('Predicted Labels (Channel 0)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model._model.predict(val_ds)  # Use the underlying Keras model\n",
    "# Select the first image in the batch\n",
    "sample_index = 0  # Index of the sample in the batch\n",
    "channel_index = 1  # Select the first channel to visualize\n",
    "for input_data, ground_truth in val_ds.take(1):  # Taking just one batch from val_ds\n",
    "    # Extract data for visualization\n",
    "    predicted_labels = model._model.predict(input_data)\n",
    "    ground_truth_image = ground_truth[sample_index, 0, :, :, channel_index]  # Shape: (200, 200)\n",
    "    predicted_image = predicted_labels[sample_index,0,  :, :, channel_index]  # Shape: (200, 200)\n",
    "\n",
    "    # Visualize the ground truth and predictions\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Ground Truth Visualization\n",
    "    axes[0].imshow(ground_truth_image, cmap='viridis')\n",
    "    axes[0].set_title('Ground Truth (Channel 0)')\n",
    "\n",
    "    # Prediction Visualization\n",
    "    axes[1].imshow(predicted_image, cmap='viridis')\n",
    "    axes[1].set_title('Predicted Labels (Channel 0)')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_ds.take(1):\n",
    "    print(type(batch))  # Check the type\n",
    "    #print(batch)        # Print batch content to inspect its structure\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['spatiotemporal'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract a single batch from the training dataset\n",
    "for input_data, ground_truth in train_ds.take(1):  # Take one batch\n",
    "    # Dynamically fetch batch size and channels\n",
    "    batch_size = 25  # Number of samples in the batch\n",
    "    num_channels_input = 34 # Input channels\n",
    "    num_channels_ground_truth = 5  # Ground truth channels\n",
    "\n",
    "    \n",
    "    # Number of samples to visualize (adjust based on batch size)\n",
    "    num_samples_to_plot = min(4, batch_size)  # Plot at most 4 samples\n",
    "\n",
    "    # Plot input data and corresponding ground truth\n",
    "    for i in range(num_samples_to_plot):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        # Input Data Visualization (Select Channel 0 for visualization)\n",
    "        axes[0].imshow(input_data['spatiotemporal'][i, :, :, 2], cmap='viridis')  # Adjust channel index if needed\n",
    "        axes[0].set_title(f\"Input Data - Sample {i+1}\")\n",
    "\n",
    "        # Ground Truth Visualization (Select Channel 0 for visualization)\n",
    "        axes[1].imshow(ground_truth[i,0, :, :, 0], cmap='viridis')  # Adjust channel index if needed\n",
    "        axes[1].set_title(f\"Ground Truth - Sample {i+1}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    break  # Exit after visualizing one batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(train_ds))\n",
    "{key: tensor.shape for key, tensor in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test calling the model on some training data\n",
    "inputs, labels = next(iter(train_ds))\n",
    "prediction = model.call(inputs)\n",
    "print(\"Prediction shape:\", prediction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
