{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Model Training Notebook\n",
    "\n",
    "Train a Flood ConvLSTM Model using `usl_models` lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pathlib\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from usl_models.flood_ml import constants\n",
    "from usl_models.flood_ml.model import FloodModel\n",
    "from usl_models.flood_ml import dataset\n",
    "from usl_models.flood_ml import visualizer\n",
    "from usl_models.flood_ml import eval\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "sim_names = [\"Manhattan-config_v1/Rainfall_Data_1.txt\"]\n",
    "filecache_dir = pathlib.Path(\"/home/shared/climateiq/filecache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Download dataset (only needs to be run the first time)\n",
    "# dataset.download_dataset(sim_names, dataset_splits=[\"train\"], output_path=filecache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and train model.\n",
    "train_dataset = dataset.load_dataset_windowed_cached(\n",
    "    filecache_dir=filecache_dir,\n",
    "    sim_names=sim_names,\n",
    "    batch_size=4,\n",
    "    dataset_split=\"train\",\n",
    ")\n",
    "model = FloodModel(\n",
    "    FloodModel.Params(\n",
    "        lstm_units=32,\n",
    "        lstm_kernel_size=3,\n",
    "        lstm_dropout=0.2,\n",
    "        lstm_recurrent_dropout=0.2,\n",
    "        m_rainfall=6,\n",
    "        n_flood_maps=5,\n",
    "        num_features=22,\n",
    "    )\n",
    ")\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test calling the model on some data.\n",
    "inputs, labels_ = next(iter(train_dataset))\n",
    "prediction = model.call(inputs)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test calling the model for n predictions\n",
    "full_dataset = dataset.load_dataset_cached(\n",
    "    filecache_dir=filecache_dir, sim_names=sim_names, batch_size=4\n",
    ")\n",
    "inputs, labels, metadata_ = next(iter(full_dataset))\n",
    "predictions = model.call_n(inputs, n=19)\n",
    "predictions.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_maes = []\n",
    "temporal_mae, temporal_rmse = [], []\n",
    "max_mae = 0.0\n",
    "max_spatial_mae = None\n",
    "highest_error_nse = None\n",
    "highest_error_pred = None\n",
    "highest_error_label = None\n",
    "\n",
    "for prediction, label in zip(tf.unstack(predictions), tf.unstack(labels)):\n",
    "    max_pred = tf.reduce_max(prediction, axis=0)\n",
    "    max_label = tf.reduce_max(label, axis=0)\n",
    "    spatial_mae = eval.spatial_mae(max_pred, max_label)\n",
    "\n",
    "    temporal_mae.append(eval.temporal_mae(prediction, label))\n",
    "    temporal_rmse.append(eval.temporal_rmse(prediction, label))\n",
    "\n",
    "    spatial_maes.append(spatial_mae)\n",
    "\n",
    "    mae = tf.reduce_mean(spatial_mae)\n",
    "    if mae > max_mae:\n",
    "        max_mae = mae\n",
    "        max_spatial_mae = spatial_mae\n",
    "        max_mae_nse = eval.spatial_nse(prediction, label)\n",
    "        max_mae_pred = max_pred\n",
    "        max_mae_label = max_label\n",
    "\n",
    "num_test_examples = len(spatial_maes)\n",
    "overall_mae = tf.reduce_mean(tf.stack(spatial_maes))\n",
    "temporal_mae = tf.reduce_mean(tf.stack(temporal_mae), axis=0)\n",
    "temporal_rmse = tf.reduce_mean(tf.stack(temporal_rmse), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_maps(\n",
    "    \"Test\",\n",
    "    spatial_mae=max_spatial_mae,\n",
    "    nse=max_mae_nse,\n",
    "    pred=max_mae_pred,\n",
    "    label=max_mae_label,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climateiq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
